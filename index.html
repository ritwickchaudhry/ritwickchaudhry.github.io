<!DOCTYPE html>
<html lang="en-us">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="theme" content="hugo-academic">
    <meta name="generator" content="Hugo 0.55.6" />
    <meta name="author" content="Ritwick Chaudhry">
    <meta property="og:image" content="img/About/DP.jpg">

    <link rel="stylesheet" href="css/highlight.min.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/academicons.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
    <link rel="stylesheet" href="css/hugo-academic.css">
    <link rel="stylesheet" href="css/custom.css">

    <link rel="icon" type="image/png" href="img/About/DP.jpg">
    <!-- <link rel="apple-touch-icon" type="image/png" href="img/apple-touch-icon.png"> -->

    <link rel="canonical" href="https://ritwickchaudhry.github.io/">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-SWSCXLQQBY"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-SWSCXLQQBY');
    </script>

    <title>Ritwick Chaudhry</title>

</head>

<body id="top">

    <nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
        <div class="container">


            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
                <a class="navbar-brand" href="/">Ritwick Chaudhry</a>
            </div>


            <div class="collapse navbar-collapse" id="#navbar-collapse-1">


                <ul class="nav navbar-nav navbar-right">

                    <li class="nav-item"><a href="#top">Home</a></li>
                    <li class="nav-item"><a href="#updates">Updates</a></li>
                    <li class="nav-item"><a href="#publications">Publications</a></li>
                    <li class="nav-item"><a href="#patents">Patents</a></li>
                    <li class="nav-item"><a href="#teaching">Teaching</a></li>

                </ul>

            </div>
        </div>
    </nav>

    <span id="homepage" style="display: none"></span>

    <section id="bio" class="home-section">
        <div class="container">

            <div class="row" itemprop="author" itemscope itemtype="http://schema.org/Person">
                <div class="col-xs-12 col-md-4">
                    <div id="profile">


                        <div class="portrait" itemprop="image" style="background-image: url('img/About/DP.jpg');">
                        </div>


                        <div class="portrait-title">
                            <h2 itemprop="name">Ritwick Chaudhry</h2>
                            <h3 id="amazon_email" onmouseover="shuffle_amazon()">hover over me @ amazon.com</h3>
                            <h3 id="personal_email" onmouseover="shuffle_personal()">hover over me @ gmail.com</h3>
                            <h3 itemprop="worksFor ">Amazon Web Services</h3>
                        </div>

                        <ul class="social-icon " aria-hidden="true ">


                            <li>
                                <a href="resources/Ritwick_Chaudhry_Resume.pdf ">
                                    <i class="fa fa-file-pdf-o big-icon "></i>
                                </a>
                            </li>


                            <li>
                                <a href="https://scholar.google.com/citations?user=Kx0uWnYAAAAJ&hl=en&oi=ao ">
                                    <i class="ai ai-google-scholar big-icon "></i>
                                </a>
                            </li>


                            <li>
                                <a href="https://github.com/ritwickchaudhry/ ">
                                    <i class="fa fa-github big-icon "></i>
                                </a>
                            </li>


                            <li>
                                <a href="https://linkedin.com/in/ritwickchaudhry/ ">
                                    <i class="fa fa-linkedin big-icon "></i>
                                </a>
                            </li>


                            <li>
                                <a href="https://www.fb.com/ritwickchaudhry ">
                                    <i class="fa fa-facebook big-icon "></i>
                                </a>
                            </li>

                        </ul>

                    </div>
                </div>

                <div class="visible-sm visible-xs "></div>

                <div class="col-xs-12 col-md-8 " itemprop="description ">



                    <h1 id="biography" style="margin-top: 15%">Biography</h1>

                    <p>I am working as an Applied Scientist at <a href="https://aws.amazon.com/ai/ ">Amazon (AWS) AI </a>, focussing on developing novel technologies in Deep Learning and Computer Vision. I graduated from
                        <a href="http://cmu.edu "> Carnegie Mellon University </a> with a
                        <a href="https://csd.cmu.edu/academics/masters/overview#mscsoverview "> Masters' in Computer Science </a>, and I have completed my B.Tech from <a href="https://www.iitb.ac.in/ "> Indian Institute of Technology (IIT) Bombay </a>.
                        I have also worked for a year at <a href="https://research.adobe.com/ "> Adobe Research </a>, and recently completed an internship at <a href="https://www.uber.com/us/en/atg/research-and-development/ "> Uber Advanced Technologies Group (ATG) </a>,
                        building sophisticated joint perception/prediction models for making autonomous vehicles a reality. In the past, I have also completed research internships at <a href="https://research.adobe.com/ "> Adobe Research </a> and the
                        <a href="https://www.jhu.edu/ "> Johns Hopkins Univsersity </a> under <a href="https://suchisaria.jhu.edu/ "> Prof. Suchi Saria </a>. I have published my work in top conferences like <a href="https://cvpr2021.thecvf.com/ "> CVPR</a>,
                        <a href="https://www.aaai.org/ "> AAAI</a>,
                        <a href="https://openaccess.thecvf.com/WACV2020 "> WACV</a> and have authored 2 issued and 4 filed patents in the <a href="https://www.uspto.gov/ "> US Patent Office </a>.
                    </p>
                </div>

            </div>

            <div class="row ">
                <table class='about-edu'>
                    <tr>
                        <td align="middle" width="16% " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">
                            <a href="http://iitb.ac.in "><img src="img/About/IITB.png " width="60% "></a>
                        </td>

                        <td align="middle" width="16% " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">
                            <a href="http://jhu.edu/ "><img src="img/About/JHU.png " width="80% "></a>
                        </td>

                        <td align="middle" width="16% " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">
                            <a href="http://research.adobe.com/ "><img src="img/About/Adobe.png " width="40% "></a>
                        </td>

                        <td align="middle" width="16% " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">
                            <a href="http://research.adobe.com/ "><img src="img/About/Adobe.png " width="40% "></a>
                        </td>
                        <td align="middle" width="16% " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">
                            <a href="http://cmu.edu "><img src="img/About/CMU.png " width="80% "></a>
                        </td>

                        <td align="middle" width="16% " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">
                            <a href="http://aws.amazon.com/ai "><img src="img/About/AWS.png " width="60% "></a>
                        </td>

                    </tr>

                    <tr>


                        <td align="center " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">B.Tech, Computer Science IIT Bombay<br>2014 - 2018</td>

                        <td align="center " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">Research Intern<br>Johns Hopkins University<br>Summer 2016</td>

                        <td align="center " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">Research Intern<br>Adobe Research<br>Summer 2017</td>

                        <td align="center " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">Research Engineer<br>Adobe Research<br>Jun 2018 - Jul 2019</td>

                        <td align="center " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">MS in CS, Carnegie Mellon University<br>Aug 2019 - Dec 2020</td>

                        <td align="center " style="vertical-align: middle; background-color: rgba(255, 255, 255, 1) ">Applied Scientist<br>AWS AI<br>Feb 2021 - Present</td>

                    </tr>

                </table>

            </div>


        </div>

    </section>

























    <section id="updates" class="home-section ">
        <div class="container ">
            <div class="row ">
                <div class="col-xs-0 col-md-4 section-heading "></div>
                <div class="col-xs-12 col-md-8 section-heading " style="margin-bottom: 1em; ">
                    <h1>Updates</h1>

                </div>
                <div class="col-xs-0 col-md-1 "></div>
                <div class="col-xs-12 col-md-11" style="height: 250px; margin: 0em; overflow-y: auto;">
                    <!-- DM Patent -->
                    <div class="col-xs-2 col-md-2 update-dates">[Oct 2021]</div>
                    <div class="col-xs-10 col-md-10">Our Patent on <a href="https://patents.google.com/patent/US20210248576A1/en ">System to facilitate exchange of data segments between data aggregators and data consumers</a> has been issued in the <a href="https://www.uspto.gov/">US Patent Office</a> </div>
                    <!-- CVPR Talk -->
                    <div class="col-xs-2 col-md-2 update-dates">[Jun 2021]</div>
                    <div class="col-xs-10 col-md-10">Invited to give a talk at the <a href="https://cqaw.github.io/">CVPR Workshop on Chart Question Answering</a>. The recorded session is available <a href="https://www.youtube.com/watch?v=2tUP_lTglpw&t=10488s">online</a>.</div>
                    <!-- Tracking -->
                    <div class="col-xs-2 col-md-2 update-dates">[Jun 2021]</div>
                    <div class="col-xs-10 col-md-10">Our work on <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Harley_Track_Check_Repeat_An_EM_Approach_to_Unsupervised_Tracking_CVPR_2021_paper.html">Track, Check, Repeat: An EM Approach to Unsupervised Tracking</a> was
                        presented at <a href="https://cvpr2021.thecvf.com/">CVPR 2021</a>.</div>
                    <!-- CoLearn Patent -->
                    <div class="col-xs-2 col-md-2 update-dates">[Mar 2021]</div>
                    <div class="col-xs-10 col-md-10">Our patent on <a href="https://patents.google.com/patent/US10943497B2/en ">Personalized e-learning using a deep-learning based knowledge tracing and hint-taking propensity model</a> has been issued in the <a href="https://www.uspto.gov/">US Patent Office</a></div>
                    <!-- AAAI 2021 -->
                    <div class="col-xs-2 col-md-2 update-dates">[Feb 2021]</div>
                    <div class="col-xs-10 col-md-10">Presented our work
                        <a href="https://www.aaai.org/AAAI21Papers/AAAI-3211.MaheshwariP.pdf">Scene Graph Embeddings using Relative Similarity Supervision</a> at <a href=" https://aaai.org/Conferences/AAAI-21/ ">AAAI 2021</a>.</div>
                    <!-- AWS -->
                    <div class="col-xs-2 col-md-2 update-dates">[Feb 2021]</div>
                    <div class="col-xs-10 col-md-10">Started working as an Applied Scientist at
                        <a href="https://aws.amazon.com/ai/">Amazon Web Services (AWS) AI</a> in the Bay Area.</div>
                    <!-- CMU -->
                    <div class="col-xs-2 col-md-2 update-dates">[Dec 2020]</div>
                    <div class="col-xs-10 col-md-10">Graduated from <a href="http://cmu.edu "> Carnegie Mellon University </a> with a
                    <a href="https://csd.cmu.edu/academics/masters/overview#mscsoverview "> Masters' in Computer Science</a>, securing a GPA of <font style="color: red">4.29 out of 4.00</font>.</div>
                </div>
            </div>
        </div>
    </section>



























    <section id="publications" class="home-section ">
        <div class="container ">

            <div class="row " style="margin: 2em 0 ">

                <div class="col-xs-0 col-md-4 "></div>
                <div class="col-xs-12 col-md-8 " style="margin-bottom: 1em; ">
                    <h1>Publications</h1>
                </div>
                <ul class="fa-ul ">

                    <!-- SG -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-0 col-md-4 ">
                            <span>
                            <img class="pub-img " style="margin-right: auto; margin-left: auto; " src="img/Papers/SG.png ">
                            </img>
                          </span>
                        </div>
                        <div class="col-xs-12 col-md-8 ">

                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon " aria-hidden="true "></i>

                                <span itemprop="name ">Scene Graph Embeddings Using Relative Similarity Supervision</span>
                                <div class="pub-list-item " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <a href='https://paridhimaheshwari2708.github.io/'>Paridhi Maheshwari <sup>&dagger;</sup></a>,
                                        <b style="color: black ">Ritwick Chaudhry <sup>&dagger;</sup></b>,
                                        <a href='https://research.adobe.com/person/vishwa-vinay/'>Vishwa Vinay</a>
                                        <a style="color: black; "><small>(&dagger; denotes equal contribution)</small></a>
                                    </div>
                                    <div class="pub-publication ">
                                        AAAI 2021
                                    </div>
                                    <p>
                                        <a type="button" class="btn btn-primary btn-outline btn-xs " data-toggle="modal " data-target="#sg_modal ">Abstract</a>
                                        <a class="btn btn-primary btn-outline btn-xs " href="https://www.aaai.org/AAAI21Papers/AAAI-3211.MaheshwariP.pdf "> PDF</a>
                                        <a class="btn btn-primary btn-outline btn-xs " href="https://slideslive.com/38948276/scene-graph-embeddings-using-relative-similarity-supervision ">Talk</a>
                                        <a class="btn btn-primary btn-outline btn-xs " onclick="sg() ">BibTeX</a>
                                        <!-- Modal -->
                                        <div class="modal fade " id="sg_modal " tabindex="-1 " role="dialog " aria-labelledby="sg_modal_label " aria-hidden="true ">
                                            <div class="modal-dialog " role="document ">
                                                <div class="modal-content ">
                                                    <div class="modal-header ">
                                                        <button type="button " class="close " data-dismiss="modal " aria-label="Close ">
                                                        <span aria-hidden="true ">&times;</span>
                                                      </button>
                                                        <h5 class="modal-title " id="sg_modal_label ">Scene Graph Embeddings Using Relative Similarity Supervision</h3>
                                                    </div>
                                                    <div class="modal-body ">
                                                        Scene graphs are a powerful structured representation of the underlying content of images, and embeddings derived from them have been shown to be useful in multiple downstream tasks. In this work, we employ a graph convolutional network to exploit structure
                                                        in scene graphs and produce image embeddings useful for semantic image retrieval. Different from classification-centric supervision traditionally available for learning image representations, we
                                                        address the task of learning from relative similarity labels in a ranking context. Rooted within the contrastive learning paradigm, we propose a novel loss function that operates on pairs of similar
                                                        and dissimilar images and imposes relative ordering between them in embedding space. We demonstrate that this Ranking loss, coupled with an intuitive triple sampling strategy, leads to robust representations
                                                        that outperform well-known contrastive losses on the retrieval task. In addition, we provide qualitative evidence of how retrieved results that utilize structured scene information capture the global
                                                        context of the scene, different from visual similarity search.
                                                    </div>
                                                    <div class="modal-footer ">
                                                        <button type="button " class="btn btn-secondary " data-dismiss="modal ">Close</button>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                        <pre id="sg_bib" , style="display:none ">
@inproceedings{maheshwari2021scene,
  title={Scene Graph Embeddings Using Relative Similarity Supervision},
  author={Maheshwari, Paridhi and Chaudhry, Ritwick and Vinay, Vishwa},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={3},
  pages={2328--2336},
  year={2021}
}
                                      </pre>
                                    </p>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- TRACKING -->
                    <div class="row " style="margin-bottom: 1.5em 0 ">
                        <div class="col-xs-0 col-md-4 ">
                            <span>
                            <img class="pub-img " style="width: 50%; margin-right: auto; margin-left: auto; " src="img/Papers/Tracking.gif ">
                            </img>
                          </span>
                        </div>
                        <div class="col-xs-12 col-md-8 ">

                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon " aria-hidden="true "></i>

                                <span itemprop="name ">Track, Check, Repeat: An EM Approach to Unsupervised Tracking</span>
                                <div class="pub-list-item " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <a href='https://www.cs.cmu.edu/~aharley/'>Adam W. Harley</a>,
                                        <a href='https://zuoym15.github.io/'>Yiming Zuo</a>,
                                        <a href='https://wenj.github.io/'>Jing Wen</a>,
                                        <a href='https://scholar.google.com/citations?user=9TPamcgAAAAJ&hl=en'>Ayush Mangal</a>,
                                        <a href='https://scholar.google.com/citations?user=i566pacAAAAJ&hl=en'>Shubhankar Potdar</a>,
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                        <a href='https://www.cs.cmu.edu/~katef/'>Katerina Fragkiadaki</a>,
                                    </div>
                                    <div class="pub-publication ">
                                        CVPR 2021
                                    </div>
                                    <p>
                                        <a type="button " class="btn btn-primary btn-outline btn-xs " data-toggle="modal " data-target="#tracking_modal ">Abstract</a>
                                        <a class="btn btn-primary btn-outline btn-xs " href="https://openaccess.thecvf.com/content/CVPR2021/papers/Harley_Track_Check_Repeat_An_EM_Approach_to_Unsupervised_Tracking_CVPR_2021_paper.pdf "> PDF</a>
                                        <a class="btn btn-primary btn-outline btn-xs " href="https://www.youtube.com/watch?v=Jg2f5fkgxZo ">Video</a>
                                        <a class="btn btn-primary btn-outline btn-xs " onclick="tracking() ">BibTeX</a>
                                        <!-- Modal -->
                                        <div class="modal fade " id="tracking_modal " tabindex="-1 " role="dialog " aria-labelledby="tracking_modal_label " aria-hidden="true ">
                                            <div class="modal-dialog " role="document ">
                                                <div class="modal-content ">
                                                    <div class="modal-header ">
                                                        <button type="button " class="close " data-dismiss="modal " aria-label="Close ">
                                                        <span aria-hidden="true ">&times;</span>
                                                      </button>
                                                        <h5 class="modal-title " id="tracking_modal_label ">Track, Check, Repeat: An EM Approach to Unsupervised Tracking</h3>
                                                    </div>
                                                    <div class="modal-body ">
                                                        We propose an unsupervised method for detecting and tracking moving objects in 3D, in unlabelled RGB-D videos. The method begins with classic handcrafted techniques for segmenting objects using motion cues: we estimate optical flow and camera motion,
                                                        and conservatively segment regions that appear to be moving independently of the background. Treating these initial segments as pseudo-labels, we learn an ensemble of appearance-based 2D and 3D detectors,
                                                        under heavy data augmentation. We use this ensemble to detect new instances of the "moving " type, even if they are not moving, and add these as new pseudo-labels. Our method is an expectation-maximization
                                                        algorithm, where in the expectation step we fire all modules and look for agreement among them, and in the maximization step we re-train the modules to improve this agreement. The constraint of ensemble
                                                        agreement helps combat contamination of the generated pseudo-labels (during the E step), and data augmentation helps the modules generalize to yet-unlabelled data (during the M step). We compare
                                                        against existing unsupervised object discovery and tracking methods, using challenging videos from CATER and KITTI, and show strong improvements over the state-of-the-art.
                                                    </div>
                                                    <div class="modal-footer ">
                                                        <button type="button " class="btn btn-secondary " data-dismiss="modal ">Close</button>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                        <pre id="tracking_bib " , style="display:none ">
@InProceedings{Harley_2021_CVPR,
    author    = {Harley, Adam W. and Zuo, Yiming and Wen, Jing and Mangal, Ayush and Potdar, Shubhankar and Chaudhry, Ritwick and Fragkiadaki, Katerina},
    title     = {Track, Check, Repeat: An EM Approach to Unsupervised Tracking},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {16581-16591}
}
                                      </pre>
                                    </p>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- LEAF QA-->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-0 col-md-4 ">
                            <span>
                            <img class="pub-img " style="margin-right: auto; margin-left: auto; " src="img/Papers/LEAFQA.png ">
                            </img>
                          </span>
                        </div>
                        <div class="col-xs-12 col-md-8 ">

                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon " aria-hidden="true "></i>

                                <span itemprop="name ">LEAF-QA: Locate, Encode & Attend for Figure question answering</span>
                                <div class="pub-list-item " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                        <a href='https://research.adobe.com/person/sumit-shekhar/'>Sumit Shekhar</a>,
                                        <a href='https://www.linkedin.com/in/utkarsh357/?originalSubdomain=in'>Utkarsh Gupta</a>
                                        <a href="https://pranavmaneriker.github.io/ ">Pranav Maneriker</a>,
                                        <a href="https://www.linkedin.com/in/prann-bansal/ ">Prann Bansal</a>,
                                        <a href="https://www.linkedin.com/in/ajay-joshi-839563138/ ">Ajay Joshi</a>
                                    </div>
                                    <div class="pub-publication ">
                                        WACV 2020, Invited Talk at CVPR 2021 Workshop on Chart Question Answering (CQAW)
                                    </div>
                                    <p>
                                        <a type="button " class="btn btn-primary btn-outline btn-xs " data-toggle="modal " data-target="#leafqa_modal ">Abstract</a>
                                        <a class="btn btn-primary btn-outline btn-xs " href="https://openaccess.thecvf.com/content_WACV_2020/papers/Chaudhry_LEAF-QA_Locate_Encode__Attend_for_Figure_Question_Answering_WACV_2020_paper.pdf "> PDF</a>
                                        <a class="btn btn-primary btn-outline btn-xs " onclick="leafqa() ">BibTeX</a>
                                        <a class="btn btn-primary btn-outline btn-xs " href="https://www.youtube.com/watch?v=2tUP_lTglpw&t=10488s ">Talk</a>
                                        <!-- Modal -->
                                        <div class="modal fade " id="leafqa_modal " tabindex="-1 " role="dialog " aria-labelledby="leafqa_modal_label " aria-hidden="true ">
                                            <div class="modal-dialog " role="document ">
                                                <div class="modal-content ">
                                                    <div class="modal-header ">
                                                        <button type="button " class="close " data-dismiss="modal " aria-label="Close ">
                                                        <span aria-hidden="true ">&times;</span>
                                                      </button>
                                                        <h5 class="modal-title " id="leafqa_modal_label ">LEAF-QA: Locate, Encode & Attend for Figure question answering</h3>
                                                    </div>
                                                    <div class="modal-body ">
                                                        We introduce LEAF-QA, a comprehensive dataset of 250,000 densely annotated figures/charts, constructed from real-world open data sources, along with 2 million question-answer (QA) pairs querying the structure and semantics of these charts. LEAF-QA highlights
                                                        the problem of multimodal QA, which is notably different from conventional visual QA (VQA), and has recently gained interest in the community. Furthermore, LEAF-QA is significantly more complex than
                                                        previous attempts at chart QA, viz. FigureQA and DVQA, which present only limited variations in chart data. LEAF-QA being constructed from real-world sources, requires a novel architecture to enable
                                                        question answering. To this end, LEAF-Net, a deep architecture involving chart element localization, question and answer encoding in terms of chart elements, and an attention network is proposed.
                                                        Different experiments are conducted to demonstrate the challenges of QA on LEAF-QA. The proposed architecture, LEAF-Net also considerably advances the current state-of-the-art on FigureQA and DVQA.
                                                    </div>
                                                    <div class="modal-footer ">
                                                        <button type="button " class="btn btn-secondary " data-dismiss="modal ">Close</button>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                        <pre id="leafqa_bib " , style="display:none ">
@InProceedings{Chaudhry_2020_WACV,
author = {Chaudhry, Ritwick and Shekhar, Sumit and Gupta, Utkarsh and Maneriker, Pranav and Bansal, Prann and Joshi, Ajay},
title = {LEAF-QA: Locate, Encode & Attend for Figure Question Answering},
booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
month = {March},
year = {2020}
}
                                      </pre>
                                    </p>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- Tomography -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-0 col-md-4 ">
                            <span>
                            <img class="pub-img " style="margin-right: auto; margin-left: auto; " src="img/Papers/Tomography.png ">
                            </img>
                          </span>
                        </div>
                        <div class="col-xs-12 col-md-8 ">

                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon " aria-hidden="true "></i>

                                <span itemprop="name ">AB Initio Tomography With Object Heterogeneity and Unknown Viewing Parameters</span>
                                <div class="pub-list-item " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <a href='https://arunabh98.github.io/about/'>Arunabh Ghosh<sup>&dagger;</sup></a>,
                                        <b style="color: black ">Ritwick Chaudhry<sup>&dagger;</sup></b>,
                                        <a href='https://www.cse.iitb.ac.in/~ajitvr/'>Ajit Rajwade</a>
                                        <a style="color: black; "><small>(&dagger; denotes equal contribution)</small></a>
                                    </div>
                                    <div class="pub-publication ">
                                        IEEE ICIP 2019
                                    </div>
                                    <p>
                                        <a type="button " class="btn btn-primary btn-outline btn-xs " data-toggle="modal " data-target="#tomography_modal ">Abstract</a>
                                        <a class="btn btn-primary btn-outline btn-xs " href="https://par.nsf.gov/servlets/purl/10188725 ">PDF</a>
                                        <a class="btn btn-primary btn-outline btn-xs " onclick="tomography() ">BibTeX</a>
                                        <!-- Modal -->
                                        <div class="modal fade " id="tomography_modal " tabindex="-1 " role="dialog " aria-labelledby="tomography_modal_label " aria-hidden="true ">
                                            <div class="modal-dialog " role="document ">
                                                <div class="modal-content ">
                                                    <div class="modal-header ">
                                                        <button type="button " class="close " data-dismiss="modal " aria-label="Close ">
                                                        <span aria-hidden="true ">&times;</span>
                                                      </button>
                                                        <h5 class="modal-title " id="tomography_modal_label ">AB Initio Tomography With Object Heterogeneity and Unknown Viewing Parameters</h3>
                                                    </div>
                                                    <div class="modal-body ">
                                                        In this paper, we present an algorithm to automatically construct all the conformations of a heterogeneous planar object from their tomographic projections at random unknown view angles. Our statistically motivated approach can reveal and analyze the
                                                        heterogeneity in the projection dataset and segregate the projections belonging to different structures without requiring prior structural information or templates, expert human intervention or even
                                                        the knowledge of the number of conformations present in the sample. Even in the presence of high noise variance (low SNR) and a large number of conformations, our algorithm can estimate the structures
                                                        of each conformation to a high degree of accuracy. We demonstrate the broad applicability of our algorithm by evaluating its performance on synthetic 2D datasets of well-known protein complexes such
                                                        as Lipase under varying levels of noise and different number of conformations.
                                                    </div>
                                                    <div class="modal-footer ">
                                                        <button type="button " class="btn btn-secondary " data-dismiss="modal ">Close</button>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                        <pre id="tomography_bib " , style="display:none ">
@inproceedings{ghosh2019ab,
  title={AB Initio Tomography With Object Heterogeneity and Unknown Viewing Paramete},
  author={Ghosh, Arunabh and Chaudhry, Ritwick and Rajwade, Ajit},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)},
  pages={1257--1261},
  year={2019},
  organization={IEEE}
}
                                      </pre>
                                    </p>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- ICDAR -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-0 col-md-4 ">
                            <span>
                            <img class="pub-img " style="margin-right: auto; margin-left: auto; " src="img/Papers/ICDAR.png ">
                            </img>
                          </span>
                        </div>
                        <div class="col-xs-12 col-md-8 ">

                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon " aria-hidden="true "></i>

                                <span itemprop="name ">ICDAR 2019 Competition on Harvesting Raw Tables from Infographics (CHART-Infographics)</span>
                                <div class="pub-list-item " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <a href='https://scholar.google.com/citations?user=1uxS5wsAAAAJ&hl=en'>Kenny Davila</a>,
                                        <a href='https://scholar.google.co.in/citations?user=xfT1XQkAAAAJ&hl=en'>Bhargava Urala Kota</a>,
                                        <a href='https://www.buffalo.edu/cubs/members/srirangaraj-setlur.html'>Srirangaraj Setlur</a>,
                                        <a href='https://www.buffalo.edu/cubs/members/venu-govindaraju.html'>Venu Govindaraju</a>,
                                        <a href='https://research.adobe.com/person/chris-tensmeyer/'>Christopher Tensmeyer</a>,
                                        <a href='https://research.adobe.com/person/sumit-shekhar/'>Sumit Shekhar</a>
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                    </div>
                                    <div class="pub-publication ">
                                        IEEE ICDAR 2019
                                    </div>
                                    <p>
                                        <a type="button " class="btn btn-primary btn-outline btn-xs " data-toggle="modal " data-target="#icdar_mod al ">Abstract</a>
                                        <a class="btn btn-primary btn-outline btn-xs " href="https://par.nsf.gov/servlets/purl/10188725 ">PDF</a>
                                        <a class="btn btn-primary btn-outline btn-xs " onclick="icdar() ">BibTeX</a>
                                        <!-- Modal -->
                                        <div class="modal fade " id="icdar_modal " tabindex="-1 " role="dialog " aria-labelledby="icdar_modal_label " aria-hidden="true ">
                                            <div class="modal-dialog " role="document ">
                                                <div class="modal-content ">
                                                    <div class="modal-header ">
                                                        <button type="button " class="close " data-dismiss="modal " aria-label="Close ">
                                                        <span aria-hidden="true ">&times;</span>
                                                      </button>
                                                        <h5 class="modal-title " id="icdar_modal_label ">ICDAR 2019 Competition on Harvesting Raw Tables from Infographics (CHART-Infographics)</h3>
                                                    </div>
                                                    <div class="modal-body ">
                                                        This work summarizes the results of the first Competition on Harvesting Raw Tables from Infographics (ICDAR 2019 CHART-Infographics). The complex process of automatic chart recognition is divided into multiple tasks for the purpose of this competition,
                                                        including Chart Image Classification (Task 1), Text Detection and Recognition (Task 2), Text Role Classification (Task 3), Axis Analysis (Task 4), Legend Analysis (Task 5), Plot Element Detection
                                                        and Classification (Task 6.a), Data Extraction (Task 6.b), and End-to-End Data Extraction (Task 7). We provided a large synthetic training set and evaluated submitted systems using newly proposed
                                                        metrics on both synthetic charts and manually-annotated real charts taken from scientific literature. A total of 8 groups registered for the competition out of which 5 submitted results for tasks
                                                        1-5. The results show that some tasks can be performed highly accurately on synthetic …
                                                    </div>
                                                    <div class="modal-footer ">
                                                        <button type="button " class="btn btn-secondary " data-dismiss="modal ">Close</button>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                        <pre id="icdar_bib " , style="display:none ">
@inproceedings{davila2019icdar,
  title={ICDAR 2019 Competition on Harvesting Raw Tables from Infographics (CHART-Infographics)},
  author={Davila, Kenny and Kota, Bhargava Urala and Setlur, Srirangaraj and Govindaraju, Venu and Tensmeyer, Christopher and Shekhar, Sumit and Chaudhry, Ritwick},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={1594--1599},
  year={2019},
  organization={IEEE}
}
                                      </pre>
                                    </p>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- CoLearn -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-0 col-md-4 ">
                            <span>
                            <img class="pub-img " style="margin-right: auto; margin-left: auto; " src="img/Papers/CoLearn.png ">
                            </img>
                          </span>
                        </div>
                        <div class="col-xs-12 col-md-8 ">

                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon " aria-hidden="true "></i>

                                <span itemprop="name ">Modeling Hint-Taking Behavior and Knowledge State of Students with Multi-Task Learning</span>
                                <div class="pub-list-item " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                        <a href='https://harvineet.github.io/'>Harvineet Singh</a>,
                                        <a href='http://web.cs.ucla.edu/~dogga/'>Pradeep Dogga</a>,
                                        <a href='https://research.adobe.com/person/shiv-kumar-saini/'>Shiv Kumar Saini</a>,
                                    </div>
                                    <div class="pub-publication ">
                                        MedialEval 2018
                                    </div>
                                    <p>
                                        <a type="button " class="btn btn-primary btn-outline btn-xs " data-toggle="modal " data-target="#colearn_modal ">Abstract</a>
                                        <a class="btn btn-primary btn-outline btn-xs " href="https://files.eric.ed.gov/fulltext/ED593119.pdf ">PDF</a>
                                        <a class="btn btn-primary btn-outline btn-xs " onclick="colearn() ">BibTeX</a>
                                        <!-- Modal -->
                                        <div class="modal fade " id="colearn_modal " tabindex="-1 " role="dialog " aria-labelledby="colearn_modal_label " aria-hidden="true ">
                                            <div class="modal-dialog " role="document ">
                                                <div class="modal-content ">
                                                    <div class="modal-header ">
                                                        <button type="button " class="close " data-dismiss="modal " aria-label="Close ">
                                                        <span aria-hidden="true ">&times;</span>
                                                      </button>
                                                        <h5 class="modal-title " id="colearn_modal_label ">Modeling Hint-Taking Behavior and Knowledge State of Students with Multi-Task Learning</h3>
                                                    </div>
                                                    <div class="modal-body ">
                                                        Interactive learning environments facilitate learning by providing hints to fill the gaps in the understanding of a concept. Studies suggest that hints are not used optimally by learners. Either they are used unnecessarily or not used at all. It has been
                                                        shown that learning outcomes can be improved by providing hints when needed. An effective hinttaking prediction model can be used by a learning environment to make adaptive decisions on whether to
                                                        withhold or provide hints. Past work on student behavior modeling has focused extensively on the task of modeling a learner’s state of knowledge over time, referred to as knowledge tracing. The other
                                                        aspects of a learner’s behavior such as tendency to use hints has garnered limited attention. Past knowledge tracing models either ignore the questions where a hint was taken or label hints taken
                                                        as an incorrect response. We propose a multi-task memory-augmented deep learning model to jointly predict the hint-taking and the knowledge tracing task. The model incorporates the effect of past
                                                        responses as well as hints taken on both the tasks. We apply the model on two datasets–ASSISTments 2009-10 skill builder dataset and Junyi Academy Math Practicing Log. The results show that deep
                                                        learning models efficiently leverage the sequential information present in a learner’s responses. The proposed model significantly out-performs the past work on hint prediction by at least 12% points.
                                                        Moreover, we demonstrate that jointly modeling the two tasks improves performance consistently across the tasks and the datasets, albeit by a small amount.
                                                    </div>
                                                    <div class="modal-footer ">
                                                        <button type="button " class="btn btn-secondary " data-dismiss="modal ">Close</button>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                        <pre id="colearn_bib " , style="display:none ">
@article{chaudhry2018modeling,
  title={Modeling Hint-Taking Behavior and Knowledge State of Students with Multi-Task Learning.},
  author={Chaudhry, Ritwick and Singh, Harvineet and Dogga, Pradeep and Saini, Shiv Kumar},
  journal={International Educational Data Mining Society},
  year={2018},
  publisher={ERIC}
}
                                      </pre>
                                    </p>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- VideoMem -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-0 col-md-4 ">
                            <span>
                            <img class="pub-img " style="margin-right: auto; margin-left: auto; " src="img/Papers/VideoMemorability.png ">
                            </img>
                          </span>
                        </div>
                        <div class="col-xs-12 col-md-8 ">

                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon " aria-hidden="true "></i>

                                <span itemprop="name ">Show and Recall@ MediaEval 2018 ViMemNet: Predicting Video Memorability</span>
                                <div class="pub-list-item " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                        <a href='https://www.linkedin.com/in/manoj-kilaru-0753b4b4/'>Manoj Kilaru</a>,
                                        <a href='https://research.adobe.com/person/sumit-shekhar/'>Sumit Shekhar</a>

                                    </div>
                                    <div class="pub-publication ">
                                        Educational Data Mining 2018
                                    </div>
                                    <p>
                                        <a type="button " class="btn btn-primary btn-outline btn-xs " data-toggle="modal " data-target="#videomem_modal ">Abstract</a>
                                        <a class="btn btn-primary btn-outline btn-xs " href="http://ceur-ws.org/Vol-2283/MediaEval_18_paper_15.pdf ">PDF</a>
                                        <a class="btn btn-primary btn-outline btn-xs " onclick="videomem() ">BibTeX</a>
                                        <!-- Modal -->
                                        <div class="modal fade " id="videomem_modal " tabindex="-1 " role="dialog " aria-labelledby="videomem_modal_label " aria-hidden="true ">
                                            <div class="modal-dialog " role="document ">
                                                <div class="modal-content ">
                                                    <div class="modal-header ">
                                                        <button type="button " class="close " data-dismiss="modal " aria-label="Close ">
                                                        <span aria-hidden="true ">&times;</span>
                                                      </button>
                                                        <h5 class="modal-title " id="videomem_modal_label ">Show and Recall@ MediaEval 2018 ViMemNet: Predicting Video Memorability</h3>
                                                    </div>
                                                    <div class="modal-body ">
                                                        In the current age of expanding access to the Internet, there has been a flood of videos on the web. Studying the human cognitive factors that affect the consumption of these videos is becoming increasingly important, to be able to effectively organize
                                                        and curate them. One such important cognitive factor is Video Memorability, which is the ability to recall a video’s content after watching it. In this paper, we present our approach to solving the
                                                        MediaEval 2018 Predicting Media Memorability Task. We develop a 3-forked pipeline for predicting Memorability Scores, which leverages the visual image features (both low-level and high-level), the
                                                        image saliency in different video frames, and the information present in the captions. We also explore the relevance of other features such as image memorability scores of the different frames in
                                                        the video, and present a detailed analysis of the results.
                                                    </div>
                                                    <div class="modal-footer ">
                                                        <button type="button " class="btn btn-secondary " data-dismiss="modal ">Close</button>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                        <pre id="videomem_bib " , style="display:none ">
@article{chaudhry2018show,
  title={Show and Recall@ MediaEval 2018 ViMemNet: Predicting Video Memorability},
  author={Chaudhry, Ritwick and Kilaru, Manoj and Shekhar, Sumit},
  journal={MediaEval 2018},
  volume={1},
  pages={G1},
  year={2018}
}
                                      </pre>
                                    </p>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- DICTA -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-0 col-md-4 ">
                            <span>
                            <img class="pub-img " style="width:50%; margin-right: auto; margin-left: auto; " src="img/Papers/DICTA.png ">
                            </img>
                          </span>
                        </div>
                        <div class="col-xs-12 col-md-8 ">

                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon " aria-hidden="true "></i>

                                <span itemprop="name ">Tomographic reconstruction using global statistical priors</span>
                                <div class="pub-list-item " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <a href='https://preetigopal.github.io/'>Preeti Gopal</a>,
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                        <a href='https://www.cse.iitb.ac.in/~sharat/'>Sharat Chandran</a>,
                                        <a href='https://research.monash.edu/en/persons/imants-svalbe'>Imants Svalbe</a>,
                                        <a href='https://www.cse.iitb.ac.in/~ajitvr/'>Ajit Rajwade</a>
                                    </div>
                                    <div class="pub-publication ">
                                        IEEE DICTA 2017
                                    </div>
                                    <p>
                                        <a type="button " class="btn btn-primary btn-outline btn-xs " data-toggle="modal " data-target="#dicta_modal ">Abstract</a>
                                        <a class="btn btn-primary btn-outline btn-xs " href="https://arxiv.org/pdf/1712.02423.pdf ">PDF</a>
                                        <a class="btn btn-primary btn-outline btn-xs " onclick="dicta() ">BibTeX</a>
                                        <!-- Modal -->
                                        <div class="modal fade " id="dicta_modal " tabindex="-1 " role="dialog " aria-labelledby="dicta_modal_label " aria-hidden="true ">
                                            <div class="modal-dialog " role="document ">
                                                <div class="modal-content ">
                                                    <div class="modal-header ">
                                                        <button type="button " class="close " data-dismiss="modal " aria-label="Close ">
                                                        <span aria-hidden="true ">&times;</span>
                                                      </button>
                                                        <h5 class="modal-title " id="dicta_modal_label ">Tomographic reconstruction using global statistical priors</h3>
                                                    </div>
                                                    <div class="modal-body ">
                                                        Recent research in tomographic reconstruction is motivated by the need to efficiently recover detailed anatomy from limited measurements. One of the ways to compensate for the increasingly sparse sets of measurements is to exploit the information from
                                                        templates, i.e., prior data available in the form of already reconstructed, structurally similar images. Towards this, previous work has exploited using a set of global and patch based dictionary
                                                        priors. In this paper, we propose a global prior to improve both the speed and quality of tomographic reconstruction within a Compressive Sensing framework. We choose a set of potential representative
                                                        2D images referred to as templates, to build an eigenspace; this is subsequently used to guide the iterative reconstruction of a similar slice from sparse acquisition data. Our experiments across
                                                        a diverse range of datasets show that reconstruction using an appropriate global prior, apart from being faster, gives a much lower reconstruction error when compared to the state of the art.
                                                    </div>
                                                    <div class="modal-footer ">
                                                        <button type="button " class="btn btn-secondary " data-dismiss="modal ">Close</button>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                        <pre id="dicta_bib " , style="display:none ">
@inproceedings{gopal2017tomographic,
  title={Tomographic reconstruction using global statistical priors},
  author={Gopal, Preeti and Chaudhry, Ritwick and Chandran, Sharat and Svalbe, Imants and Rajwade, Ajit},
  booktitle={2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)},
  pages={1--8},
  organization={IEEE}
}
                                      </pre>
                                    </p>
                                </div>
                            </li>
                        </div>
                    </div>

            </div>
        </div>

        </ul>


        <div class="col-xs-12 col-md-12 section-heading ">


        </div>

        </div>

        </div>
    </section>


































    <section id="patents" class="home-section ">
        <div class="container ">
            <div class="row " style="margin: 2em 0 ">

                <div class="col-xs-0 col-md-4 "></div>
                <div class="col-xs-12 col-md-8 " style="margin-bottom: 1em; ">
                    <h1>Patents</h1>
                </div>
                <ul class="fa-ul ">

                    <!-- CoLearn -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-12 col-md-10 ">
                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon-lg " aria-hidden="true "></i>

                                <span itemprop="name "><a href="https://patents.google.com/patent/US10943497B2/en ">Personalized e-learning using a deep-learning based knowledge tracing and hint-taking propensity model</a></span>
                                <div class="pub-list-item " style="margin-bottom: 0.4em; " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <a href='https://research.adobe.com/person/shiv-kumar-saini/'>Shiv Kumar Saini</a>,
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                        <a href='http://web.cs.ucla.edu/~dogga/'>Pradeep Dogga</a>,
                                        <a href='https://harvineet.github.io/'>Harvineet Singh</a>,
                                    </div>
                                    <div class="pub-publication ">
                                        Patent Number: 10,943,497, Issued: 03/09/2021
                                    </div>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- DataMarketplace -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-12 col-md-10 ">
                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon-lg " aria-hidden="true "></i>

                                <span itemprop="name "><a href="https://patents.google.com/patent/US20210248576A1/en ">System to facilitate exchange of data segments between data aggregators and data consumers</a></span>
                                <div class="pub-list-item " style="margin-bottom: 0.4em; " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <a href='https://research.adobe.com/person/shiv-kumar-saini/'>Shiv Kumar Saini</a>,
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                        <a href='https://harvineet.github.io/'>Harvineet Singh</a>,
                                        <a href='https://www.linkedin.com/in/bhavya-bahl'>Bhavya Bahl</a>,
                                        <a href='https://in.linkedin.com/in/sriya-sainath'>Sriya Sainath</a>,
                                        <a href='https://in.linkedin.com/in/savvy25'>Savya Sindhu Gupta</a>,
                                    </div>
                                    <div class="pub-publication ">
                                        Patent Number: 11,151,532 Issued: 10/19/2021
                                    </div>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- Chart Question Answering -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-12 col-md-10 ">
                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon-lg " aria-hidden="true "></i>

                                <span itemprop="name "><a href="https://patents.google.com/patent/US20210224332A1/en ">Chart Question Answering</a></span>
                                <div class="pub-list-item " style="margin-bottom: 0.4em; " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <a href='https://research.adobe.com/person/sumit-shekhar/'>Sumit Shekhar</a>,
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                        <a href='https://www.linkedin.com/in/utkarsh357/?originalSubdomain=in'>Utkarsh Gupta</a>,
                                        <a href="https://www.linkedin.com/in/prann-bansal/ ">Prann Bansal</a>,
                                        <a href="https://www.linkedin.com/in/ajay-joshi-839563138/ ">Ajay Joshi</a>
                                    </div>
                                    <div class="pub-publication ">
                                        Patent Application Number: 16,749,044 Filed: 01/22/2021
                                    </div>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- Scene Graph -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-12 col-md-10 ">
                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon-lg " aria-hidden="true "></i>

                                <span itemprop="name ">Scene Graph Embeddings Using Relative Similarity Supervision</span>
                                <div class="pub-list-item " style="margin-bottom: 0.4em; " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <a href='https://paridhimaheshwari2708.github.io/'>Paridhi Maheshwari</a>,
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                        <a href='https://research.adobe.com/person/vishwa-vinay/'>Vishwa Vinay</a>
                                    </div>
                                    <div class="pub-publication ">
                                        Patent Application Number: 17,337,801 Filed: 06/03/2021
                                    </div>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- Cold Start -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-12 col-md-10 ">
                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon-lg " aria-hidden="true "></i>

                                <span itemprop="name ">Key-Value Memory Network for predicting time-series metrics of target entities</span>
                                <div class="pub-list-item " style="margin-bottom: 0.4em; " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <a href='https://in.linkedin.com/in/ayush-chauhan-3b5b3554'>Ayush Chauhan</a>,
                                        <a href='https://research.adobe.com/person/shiv-kumar-saini/'>Shiv Kumar Saini</a>,
                                        <a href='https://www.linkedin.com/in/parth-gupta-/'>Parth Gupta</a>,
                                        <a href='https://archiki.github.io/'>Archiki Prasad</a>,
                                        <a href='https://scholar.google.com/citations?user=yXtMK6wAAAAJ&hl=en'>Amireddy Prashanth Reddy</a>
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                    </div>
                                    <div class="pub-publication ">
                                        Patent Application Number: 17,337,801 Filed: 06/03/2021
                                    </div>
                                </div>
                            </li>
                        </div>
                    </div>

                    <!-- Infographics -->
                    <div class="row " style="margin: 1.5em 0 ">
                        <div class="col-xs-12 col-md-10 ">
                            <li itemscope itemtype="http://schema.org/CreativeWork ">
                                <i class="fa-li fa fa-file-text-o pub-icon-lg " aria-hidden="true "></i>

                                <span itemprop="name ">A Method for Parsing and Reflowing Infographics using Structured Lists and Groups</span>
                                <div class="pub-list-item " style="margin-bottom: 0.4em; " itemscope itemtype="http://schema.org/CreativeWork ">
                                    <div class="pub-authors " itemprop="author ">
                                        <a href='https://research.adobe.com/person/sumit-shekhar/'>Sumit Shekhar</a>,
                                        <a href='https://research.adobe.com/person/zoya-bylinskii/'>Zoya Bylinski</a>,
                                        <a href='https://www.cse.iitk.ac.in/users/tushargr/'>Tushar Gurjar</a>,
                                        <b style="color: black ">Ritwick Chaudhry</b>,
                                        <a href='https://www.linkedin.com/in/ayush-goyal-71495412b'>Ayush Goyal</a>,
                                    </div>
                                    <div class="pub-publication ">
                                        Patent Application Number: 20,030,347 Filed:
                                    </div>
                                </div>
                            </li>
                        </div>
                    </div>

            </div>
        </div>

        </ul>
        </div>
        </div>
    </section>





































    <section id="teaching" class="home-section ">
        <div class="container ">
            <div class="row ">
                <div class="col-xs-0 col-md-4 section-heading "></div>
                <div class="col-xs-12 col-md-8 section-heading ">
                    <h1>Teaching Experience</h1>

                </div>
                <div class="col-xs-0 col-md-1 "></div>
                <div class="col-xs-12 col-md-11 ">


                    <h3 id="CMU ">Carnegie Mellon University</h3>

                    <p>16720 - Computer Vision (Fall 2019), with <a href="http://www.cs.cmu.edu/~srinivas/ ">Prof. Srinivasa Narasimhan</a><br> 18661 - Intro to Machine Learning for Engineers (Spring 2019), with <a href="https://www.andrew.cmu.edu/user/gaurij/ ">Prof. Gauri Joshi</a></p>

                    <h3 id="IITB ">IIT Bombay</h3>

                    <p> CS207 - Discrete Structures (Spring 2017), with <a href="https://www.cse.iitb.ac.in/~akshayss/ ">Prof. S. Akshay</a><br> CS 347/333 - Operating Systems (Fall 2017), with <a href="https://www.cse.iitb.ac.in/~puru ">Prof. Puru Kulkarni</a><br>CS
                        228 - Login in Computer Science (Spring 2016), with <a href="https://www.cse.iitb.ac.in/~krishnas/ ">Prof. Krishna S.</a><br>CS207 - Discrete Structures (Fall 2016), with <a href="https://www.cse.iitb.ac.in/~akshayss/
                            ">Prof. S. Akshay</a><br> MA 108 - Differential Equations (Fall 2015), with <a href="http://www.math.iitb.ac.in/~dey/ ">Prof. Santanu Dey</a></p>


                </div>
            </div>
        </div>
    </section>




    <footer class="site-footer ">
        <div class="container ">
            <p class="powered-by ">

                &copy; 2021 Ritwick Chaudhry &middot; Powered by the <a href="https://github.com/gcushen/hugo-academic " target="_blank ">Academic
      theme</a> for <a href="http://gohugo.io " target="_blank ">Hugo</a>.

                <span class="pull-right " aria-hidden="true ">
        <a href="# " id="back_to_top ">
          <span class="button_icon ">
            <i class="fa fa-chevron-up fa-2x "></i>
          </span>
                </a>
                </span>

            </p>
        </div>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js "></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js "></script>
    <script src="js/jquery-1.12.3.min.js "></script>
    <script src="js/bootstrap.min.js "></script>
    <script src="js/hugo-academic.js "></script>
    <script src="js/shuffle.js "></script>
    <script src="js/bibtex.js "></script>
    <script src="https://unpkg.com/shuffle-letters "></script>

</body>

</html>
